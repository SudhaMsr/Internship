{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt_t8YZsdsdg",
        "outputId": "6d26557f-c900-4c67-c30b-3a834bfef3d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/glide-text2im\n",
            "  Cloning https://github.com/openai/glide-text2im to /tmp/pip-req-build-2ohctdk1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/glide-text2im /tmp/pip-req-build-2ohctdk1\n",
            "  Resolved https://github.com/openai/glide-text2im to commit 69b530740eb6cef69442d6180579ef5ba9ef063e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (8.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (23.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (4.65.0)\n",
            "Collecting ftfy (from glide-text2im==0.0.0)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (2022.10.31)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (1.22.4)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->glide-text2im==0.0.0) (0.2.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->glide-text2im==0.0.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->glide-text2im==0.0.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->glide-text2im==0.0.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->glide-text2im==0.0.0) (3.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->glide-text2im==0.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->glide-text2im==0.0.0) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->glide-text2im==0.0.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->glide-text2im==0.0.0) (1.3.0)\n",
            "Building wheels for collected packages: glide-text2im\n",
            "  Building wheel for glide-text2im (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glide-text2im: filename=glide_text2im-0.0.0-py3-none-any.whl size=1953625 sha256=d5320a65eaa9ad6e603e96967a1355abb458bfe66adf4ce6fb504bdcc8888f68\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qxkig97s/wheels/88/21/5e/57cab1c1078317022fe11d86e1596fdaa12260531220ac0c99\n",
            "Successfully built glide-text2im\n",
            "Installing collected packages: ftfy, glide-text2im\n",
            "Successfully installed ftfy-6.1.1 glide-text2im-0.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/glide-text2im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z4c1nwWnMgP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "\n",
        "from glide_text2im.clip.model_creation import create_clip_model\n",
        "from glide_text2im.download import load_checkpoint\n",
        "from glide_text2im.model_creation import (\n",
        "    create_model_and_diffusion,\n",
        "    model_and_diffusion_defaults,\n",
        "    model_and_diffusion_defaults_upsampler,\n",
        ")\n",
        "from glide_text2im.tokenizer.simple_tokenizer import SimpleTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laALIr57oVgZ"
      },
      "outputs": [],
      "source": [
        "has_cuda = th.cuda.is_available()\n",
        "device = th.device('cpu' if not has_cuda else 'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "-SWx-7lKoZuQ",
        "outputId": "396f49b3-0777-4d62-b7fe-e7f0d9f755d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fb28f68e13a4645b5e0f808606b4ae8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/1.54G [00:00<?, ?iB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total base parameters 385030726\n"
          ]
        }
      ],
      "source": [
        "# Create base model.\n",
        "options = model_and_diffusion_defaults()\n",
        "options['use_fp16'] = has_cuda\n",
        "options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n",
        "model, diffusion = create_model_and_diffusion(**options)\n",
        "model.eval()\n",
        "if has_cuda:\n",
        "    model.convert_to_fp16()\n",
        "model.to(device)\n",
        "model.load_state_dict(load_checkpoint('base', device))\n",
        "print('total base parameters', sum(x.numel() for x in model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "9tmh6ZHFoc3A",
        "outputId": "1358add0-7a91-489c-e825-79b608cf9c84"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffae8d0fc79940a5850118499f3e0394",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/1.59G [00:00<?, ?iB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total upsampler parameters 398361286\n"
          ]
        }
      ],
      "source": [
        "# Create upsampler model.\n",
        "options_up = model_and_diffusion_defaults_upsampler()\n",
        "options_up['use_fp16'] = has_cuda\n",
        "options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling\n",
        "model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
        "model_up.eval()\n",
        "if has_cuda:\n",
        "    model_up.convert_to_fp16()\n",
        "model_up.to(device)\n",
        "model_up.load_state_dict(load_checkpoint('upsample', device))\n",
        "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "kn6KeAzkokWT",
        "outputId": "c148cfbd-a2be-4130-af20-e315ab10e359"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd4435b91c284b31af0f17435da6acac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/346M [00:00<?, ?iB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a4693004a364e56bf61bc18a8747d99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/287M [00:00<?, ?iB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create CLIP model.\n",
        "clip_model = create_clip_model(device=device)\n",
        "clip_model.image_encoder.load_state_dict(load_checkpoint('clip/image-enc', device))\n",
        "clip_model.text_encoder.load_state_dict(load_checkpoint('clip/text-enc', device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-n2bS2sqRFt"
      },
      "outputs": [],
      "source": [
        "def show_images(batch: th.Tensor):\n",
        "    \"\"\" Display a batch of images inline. \"\"\"\n",
        "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "    display(Image.fromarray(reshaped.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFpQGabGqb6O"
      },
      "outputs": [],
      "source": [
        "# Sampling parameters\n",
        "prompt = \"sun flower\"\n",
        "batch_size = 1\n",
        "guidance_scale = 3.0\n",
        "\n",
        "# Tune this parameter to control the sharpness of 256x256 images.\n",
        "# A value of 1.0 is sharper, but sometimes results in grainy artifacts.\n",
        "upsample_temp = 0.997"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "XrV2k_hhqhz2",
        "outputId": "dd941e7c-f315-4ce0-ee1e-684c4437c072"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e2a6b82fbd42a8aead01e9119e7b42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F0E45D81930>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create the text tokens to feed to the model.\n",
        "tokens = model.tokenizer.encode(prompt)\n",
        "tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options['text_ctx']\n",
        ")\n",
        "\n",
        "# Pack the tokens together into model kwargs.\n",
        "model_kwargs = dict(\n",
        "    tokens=th.tensor([tokens] * batch_size, device=device),\n",
        "    mask=th.tensor([mask] * batch_size, dtype=th.bool, device=device),\n",
        ")\n",
        "\n",
        "# Setup guidance function for CLIP model.\n",
        "cond_fn = clip_model.cond_fn([prompt] * batch_size, guidance_scale)\n",
        "\n",
        "# Sample from the base model.\n",
        "model.del_cache()\n",
        "samples = diffusion.p_sample_loop(\n",
        "    model,\n",
        "    (batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=cond_fn,\n",
        ")\n",
        "model.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag0gW06sqog9"
      },
      "outputs": [],
      "source": [
        "tokens = model_up.tokenizer.encode(prompt)\n",
        "tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options_up['text_ctx']\n",
        ")\n",
        "\n",
        "# Create the model conditioning dict.\n",
        "model_kwargs = dict(\n",
        "    # Low-res image to upsample.\n",
        "    low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "    # Text tokens\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Sample from the base model.\n",
        "model_up.del_cache()\n",
        "up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
        "up_samples = diffusion_up.ddim_sample_loop(\n",
        "    model_up,\n",
        "    up_shape,\n",
        "    noise=th.randn(up_shape, device=device) * upsample_temp,\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model_up.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(up_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVoW0dOywS1q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}